{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d36fb98",
   "metadata": {},
   "source": [
    "### Step 1 — Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd1724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# For resume text extraction\n",
    "import fitz  \n",
    "\n",
    "# For images (OCR dataset)\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b8e63",
   "metadata": {},
   "source": [
    "### Step 2 — Define dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a72b811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"data\"\n",
    "\n",
    "IBM_HR_PATH = r\"C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\ibm_hr\"\n",
    "RESUME_PATH = r\"C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\resumes\"\n",
    "JOBS_PATH = r\"C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\job_descriptions\"\n",
    "REVIEWS_PATH = r\"C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\employee_reviews\"\n",
    "DOC_OCR_PATH = r\"C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\document_ocr\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91369f5e",
   "metadata": {},
   "source": [
    "### Step 3 — Load IBM HR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "436030aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR Dataset Loaded: (1470, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_file = [f for f in os.listdir(IBM_HR_PATH) if f.endswith(\".csv\")][0]\n",
    "hr_df = pd.read_csv(f\"{IBM_HR_PATH}/{hr_file}\")\n",
    "\n",
    "print(\"HR Dataset Loaded:\", hr_df.shape)\n",
    "hr_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c5af9",
   "metadata": {},
   "source": [
    "###  Step 4 — Load Job Descriptions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23a26da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Descriptions Loaded: (22000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>date_added</th>\n",
       "      <th>has_expired</th>\n",
       "      <th>job_board</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_type</th>\n",
       "      <th>location</th>\n",
       "      <th>organization</th>\n",
       "      <th>page_url</th>\n",
       "      <th>salary</th>\n",
       "      <th>sector</th>\n",
       "      <th>uniq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>jobs.monster.com</td>\n",
       "      <td>TeamSoft is seeing an IT Support Specialist to...</td>\n",
       "      <td>IT Support Technician Job in Madison</td>\n",
       "      <td>Full Time Employee</td>\n",
       "      <td>Madison, WI 53702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://jobview.monster.com/it-support-technici...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IT/Software Development</td>\n",
       "      <td>11d599f229a80023d2f40e7c52cd941e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>jobs.monster.com</td>\n",
       "      <td>The Wisconsin State Journal is seeking a flexi...</td>\n",
       "      <td>Business Reporter/Editor Job in Madison</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Madison, WI 53708</td>\n",
       "      <td>Printing and Publishing</td>\n",
       "      <td>http://jobview.monster.com/business-reporter-e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4cbb126dabf22159aff90223243ff2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>jobs.monster.com</td>\n",
       "      <td>Report this job About the Job DePuy Synthes Co...</td>\n",
       "      <td>Johnson &amp; Johnson Family of Companies Job Appl...</td>\n",
       "      <td>Full Time, Employee</td>\n",
       "      <td>DePuy Synthes Companies is a member of Johnson...</td>\n",
       "      <td>Personal and Household Services</td>\n",
       "      <td>http://jobview.monster.com/senior-training-lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>839106b353877fa3d896ffb9c1fe01c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>jobs.monster.com</td>\n",
       "      <td>Why Join Altec? If you’re considering a career...</td>\n",
       "      <td>Engineer - Quality Job in Dixon</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Dixon, CA</td>\n",
       "      <td>Altec Industries</td>\n",
       "      <td>http://jobview.monster.com/engineer-quality-jo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experienced (Non-Manager)</td>\n",
       "      <td>58435fcab804439efdcaa7ecca0fd783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>jobs.monster.com</td>\n",
       "      <td>Position ID#  76162 # Positions  1 State  CT C...</td>\n",
       "      <td>Shift Supervisor - Part-Time Job in Camphill</td>\n",
       "      <td>Full Time Employee</td>\n",
       "      <td>Camphill, PA</td>\n",
       "      <td>Retail</td>\n",
       "      <td>http://jobview.monster.com/shift-supervisor-pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Project/Program Management</td>\n",
       "      <td>64d0272dc8496abfd9523a8df63c184c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country country_code date_added has_expired  \\\n",
       "0  United States of America           US        NaN          No   \n",
       "1  United States of America           US        NaN          No   \n",
       "2  United States of America           US        NaN          No   \n",
       "3  United States of America           US        NaN          No   \n",
       "4  United States of America           US        NaN          No   \n",
       "\n",
       "          job_board                                    job_description  \\\n",
       "0  jobs.monster.com  TeamSoft is seeing an IT Support Specialist to...   \n",
       "1  jobs.monster.com  The Wisconsin State Journal is seeking a flexi...   \n",
       "2  jobs.monster.com  Report this job About the Job DePuy Synthes Co...   \n",
       "3  jobs.monster.com  Why Join Altec? If you’re considering a career...   \n",
       "4  jobs.monster.com  Position ID#  76162 # Positions  1 State  CT C...   \n",
       "\n",
       "                                           job_title             job_type  \\\n",
       "0               IT Support Technician Job in Madison   Full Time Employee   \n",
       "1            Business Reporter/Editor Job in Madison            Full Time   \n",
       "2  Johnson & Johnson Family of Companies Job Appl...  Full Time, Employee   \n",
       "3                    Engineer - Quality Job in Dixon            Full Time   \n",
       "4       Shift Supervisor - Part-Time Job in Camphill   Full Time Employee   \n",
       "\n",
       "                                            location  \\\n",
       "0                                  Madison, WI 53702   \n",
       "1                                  Madison, WI 53708   \n",
       "2  DePuy Synthes Companies is a member of Johnson...   \n",
       "3                                          Dixon, CA   \n",
       "4                                       Camphill, PA   \n",
       "\n",
       "                      organization  \\\n",
       "0                              NaN   \n",
       "1          Printing and Publishing   \n",
       "2  Personal and Household Services   \n",
       "3                 Altec Industries   \n",
       "4                           Retail   \n",
       "\n",
       "                                            page_url salary  \\\n",
       "0  http://jobview.monster.com/it-support-technici...    NaN   \n",
       "1  http://jobview.monster.com/business-reporter-e...    NaN   \n",
       "2  http://jobview.monster.com/senior-training-lea...    NaN   \n",
       "3  http://jobview.monster.com/engineer-quality-jo...    NaN   \n",
       "4  http://jobview.monster.com/shift-supervisor-pa...    NaN   \n",
       "\n",
       "                       sector                           uniq_id  \n",
       "0     IT/Software Development  11d599f229a80023d2f40e7c52cd941e  \n",
       "1                         NaN  e4cbb126dabf22159aff90223243ff2a  \n",
       "2                         NaN  839106b353877fa3d896ffb9c1fe01c0  \n",
       "3   Experienced (Non-Manager)  58435fcab804439efdcaa7ecca0fd783  \n",
       "4  Project/Program Management  64d0272dc8496abfd9523a8df63c184c  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_files = [f for f in os.listdir(JOBS_PATH) if f.endswith(\".csv\") or f.endswith(\".json\")]\n",
    "\n",
    "job_dfs = []\n",
    "for file in jobs_files:\n",
    "    path = f\"{JOBS_PATH}/{file}\"\n",
    "    if file.endswith(\".csv\"):\n",
    "        df = pd.read_csv(path)\n",
    "    elif file.endswith(\".json\"):\n",
    "        df = pd.read_json(path)\n",
    "    job_dfs.append(df)\n",
    "\n",
    "job_df = pd.concat(job_dfs, ignore_index=True)\n",
    "print(\"Job Descriptions Loaded:\", job_df.shape)\n",
    "job_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab60d8",
   "metadata": {},
   "source": [
    "### Step 5 — Load Employee Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9833dc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews Loaded: (355, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positionName</th>\n",
       "      <th>salary</th>\n",
       "      <th>company</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewsCount</th>\n",
       "      <th>jobTypeConsolidated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pricing Analyst</td>\n",
       "      <td>£70,000 - £85,000 a year</td>\n",
       "      <td>Urban Empire Recruitment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Permanent, Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead AI / ML / Data Science Engineer</td>\n",
       "      <td>£150,000 a year</td>\n",
       "      <td>Founding Teams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Part-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Depop</td>\n",
       "      <td>4.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Permanent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Fellow in data analysis and machine l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UCL</td>\n",
       "      <td>4.1</td>\n",
       "      <td>256.0</td>\n",
       "      <td>Permanent, Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist | Media &amp; Entertainment.</td>\n",
       "      <td>£70,000 a year</td>\n",
       "      <td>Nicholson Glover Consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Permanent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        positionName  \\\n",
       "0                                    Pricing Analyst   \n",
       "1               Lead AI / ML / Data Science Engineer   \n",
       "2                                     Data Scientist   \n",
       "3  Research Fellow in data analysis and machine l...   \n",
       "4     Senior Data Scientist | Media & Entertainment.   \n",
       "\n",
       "                     salary                      company  rating  \\\n",
       "0  £70,000 - £85,000 a year     Urban Empire Recruitment     NaN   \n",
       "1           £150,000 a year               Founding Teams     NaN   \n",
       "2                       NaN                        Depop     4.4   \n",
       "3                       NaN                          UCL     4.1   \n",
       "4            £70,000 a year  Nicholson Glover Consulting     NaN   \n",
       "\n",
       "   reviewsCount   jobTypeConsolidated  \n",
       "0           NaN  Permanent, Full-time  \n",
       "1           NaN             Part-time  \n",
       "2          34.0             Permanent  \n",
       "3         256.0  Permanent, Full-time  \n",
       "4           NaN             Permanent  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_file = [f for f in os.listdir(REVIEWS_PATH) if f.endswith(\".csv\")][0]\n",
    "reviews_df = pd.read_csv(f\"{REVIEWS_PATH}/{review_file}\")\n",
    "\n",
    "print(\"Reviews Loaded:\", reviews_df.shape)\n",
    "reviews_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d883f8",
   "metadata": {},
   "source": [
    "### Step 6 — Extract Resume Text (PDF → TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b8c6f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2484 PDF files under: C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\resumes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting PDFs:   0%|          | 0/2484 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting PDFs: 100%|██████████| 2484/2484 [00:51<00:00, 48.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted: 2484\n",
      "Failed / corrupted: 0\n",
      "CSV metadata files found (if any): ['C:\\\\Guvi\\\\Talent Intelligence & Workforce Optimization\\\\data\\\\resumes\\\\Resume\\\\Resume.csv']\n",
      "Loaded resume metadata CSV: C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\resumes\\Resume\\Resume.csv (2484, 4)\n",
      "Failed to load CSV metadata: You are trying to merge on object and int64 columns for key 'filename'. If you wish to proceed you should use pd.concat\n",
      "Saved cleaned resumes to: processed\\resumes_clean.csv\n",
      "Final dataframe shape: (2484, 4)\n"
     ]
    }
   ],
   "source": [
    "# Step 6 (improved) — Recursively extract resume text from PDFs and combine with any CSV metadata\n",
    "import os\n",
    "import fitz       # PyMuPDF\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "RESUME_PATH = r\"C:\\Guvi\\Talent Intelligence & Workforce Optimization\\data\\resumes\"   # adjust if your notebook path differs\n",
    "OUTPUT_DIR = r\"processed\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "pdf_files = []\n",
    "# Walk folder recursively and collect PDFs\n",
    "for root, dirs, files in os.walk(RESUME_PATH):\n",
    "    for fname in files:\n",
    "        if fname.lower().endswith(\".pdf\"):\n",
    "            pdf_files.append(os.path.join(root, fname))\n",
    "\n",
    "print(f\"Found {len(pdf_files)} PDF files under: {RESUME_PATH}\")\n",
    "\n",
    "resume_records = []\n",
    "corrupted_files = []\n",
    "\n",
    "# Try extracting with PyMuPDF first; fallback to pdfplumber if necessary\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Extracting PDFs\"):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        # Attempt PyMuPDF extraction\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "            doc.close()\n",
    "            if not text.strip():\n",
    "                raise ValueError(\"PyMuPDF returned empty text\")\n",
    "        except Exception:\n",
    "            # fallback to pdfplumber\n",
    "            try:\n",
    "                with pdfplumber.open(pdf_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        text += page.extract_text() or \"\"\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "        resume_records.append({\n",
    "            \"filename\": os.path.basename(pdf_path),\n",
    "            \"filepath\": pdf_path,\n",
    "            \"text\": text\n",
    "        })\n",
    "    except Exception as e:\n",
    "        corrupted_files.append({\"file\": pdf_path, \"error\": str(e)})\n",
    "\n",
    "print(f\"Successfully extracted: {len(resume_records)}\")\n",
    "print(f\"Failed / corrupted: {len(corrupted_files)}\")\n",
    "if corrupted_files:\n",
    "    print(\"Example error:\", corrupted_files[0])\n",
    "\n",
    "resume_df = pd.DataFrame(resume_records)\n",
    "\n",
    "# If there is a Resume.csv (or similar) with metadata, load and merge (best-effort)\n",
    "csv_candidates = [p for p in os.listdir(RESUME_PATH) if p.lower().endswith(\".csv\")]\n",
    "# Also check nested top-level folder named 'Resume' (some datasets use that)\n",
    "for root, dirs, files in os.walk(RESUME_PATH):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(\".csv\"):\n",
    "            csv_candidates.append(os.path.join(root, f))\n",
    "\n",
    "csv_candidates = list(dict.fromkeys(csv_candidates))  # unique\n",
    "print(\"CSV metadata files found (if any):\", csv_candidates)\n",
    "\n",
    "if csv_candidates:\n",
    "    # attempt to load the first CSV that looks like metadata\n",
    "    csv_path = csv_candidates[0] if os.path.isabs(csv_candidates[0]) else os.path.join(RESUME_PATH, csv_candidates[0])\n",
    "    try:\n",
    "        meta_df = pd.read_csv(csv_path)\n",
    "        print(\"Loaded resume metadata CSV:\", csv_path, meta_df.shape)\n",
    "        # Try to merge on filename (if filenames present in CSV)\n",
    "        if 'filename' in meta_df.columns:\n",
    "            merged = pd.merge(meta_df, resume_df, on='filename', how='left')\n",
    "            final_df = merged\n",
    "        else:\n",
    "            # if CSV has a path column or name variations, keep them separate for now\n",
    "            final_df = resume_df.copy()\n",
    "            final_df = final_df.merge(meta_df, left_on='filename', right_on=meta_df.columns[0], how='left')\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load CSV metadata:\", e)\n",
    "        final_df = resume_df.copy()\n",
    "else:\n",
    "    final_df = resume_df.copy()\n",
    "\n",
    "# Clean text lightly (single-line)\n",
    "import re\n",
    "def clean_text(s):\n",
    "    if isinstance(s, str):\n",
    "        s = re.sub(r'\\s+', ' ', s)\n",
    "        return s.strip()\n",
    "    return \"\"\n",
    "\n",
    "final_df['clean_text'] = final_df['text'].apply(clean_text)\n",
    "\n",
    "# Save result\n",
    "out_path = os.path.join(OUTPUT_DIR, \"resumes_clean.csv\")\n",
    "final_df.to_csv(out_path, index=False)\n",
    "print(\"Saved cleaned resumes to:\", out_path)\n",
    "print(\"Final dataframe shape:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419635f5",
   "metadata": {},
   "source": [
    "### Step 7 — Clean Text Columns (Jobs, Reviews, Resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a458ca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected job description column: job_description\n",
      "Detected employee review text column: positionName\n",
      "Resume cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'\\s+', ' ', text)   # remove multiple spaces/newlines\n",
    "        text = text.replace('\\n', ' ')\n",
    "        return text.strip()\n",
    "    return \"\"\n",
    "\n",
    "# ==== Clean job description text ====\n",
    "job_text_col = None\n",
    "\n",
    "possible_cols = ['description', 'job_description', 'jobdesc', 'body', 'text']\n",
    "\n",
    "for col in possible_cols:\n",
    "    if col in job_df.columns:\n",
    "        job_text_col = col\n",
    "        break\n",
    "\n",
    "print(\"Detected job description column:\", job_text_col)\n",
    "\n",
    "if job_text_col:\n",
    "    job_df['clean_description'] = job_df[job_text_col].astype(str).apply(clean_text)\n",
    "else:\n",
    "    print(\"⚠️ No job description column found to clean.\")\n",
    "\n",
    "\n",
    "# ==== Clean employee review text ====\n",
    "\n",
    "# Find the column that likely contains the review text\n",
    "review_text_col = None\n",
    "\n",
    "for col in reviews_df.columns:\n",
    "    if reviews_df[col].dtype == 'object':   # choose first text column\n",
    "        review_text_col = col\n",
    "        break\n",
    "\n",
    "print(\"Detected employee review text column:\", review_text_col)\n",
    "\n",
    "if review_text_col:\n",
    "    reviews_df['clean_review'] = reviews_df[review_text_col].astype(str).apply(clean_text)\n",
    "else:\n",
    "    print(\"⚠️ No review text column found to clean.\")\n",
    "\n",
    "\n",
    "# ==== Clean resume extracted text (if needed) ====\n",
    "\n",
    "if 'clean_text' not in resume_df.columns:\n",
    "    resume_df['clean_text'] = resume_df['text'].astype(str).apply(clean_text)\n",
    "\n",
    "print(\"Resume cleaning complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb807f0f",
   "metadata": {},
   "source": [
    "### Step 8 — Save Cleaned Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73a2dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cleaned datasets saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"processed\", exist_ok=True)\n",
    "\n",
    "hr_df.to_csv(\"processed/hr_clean.csv\", index=False)\n",
    "job_df.to_csv(\"processed/job_descriptions_clean.csv\", index=False)\n",
    "reviews_df.to_csv(\"processed/employee_reviews_clean.csv\", index=False)\n",
    "resume_df.to_csv(\"processed/resumes_clean.csv\", index=False)\n",
    "\n",
    "print(\"All cleaned datasets saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
